{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random, gc, keras, os\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t\t (113783, 4)\n",
      "Validation:\t (22255, 4)\n",
      "Test:\t\t (22391, 4)\n",
      "\n",
      "Train Landmarks:\t 14943\n",
      "Validation Landmarks:\t 7674\n",
      "Test Landmarks:\t\t 14436\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/triplet/train.csv')\n",
    "val_df = pd.read_csv('./data/triplet/validation.csv')\n",
    "test_df = pd.read_csv('./data/triplet/test.csv')\n",
    "\n",
    "print('Train:\\t\\t', train_df.shape)\n",
    "print('Validation:\\t', val_df.shape)\n",
    "print('Test:\\t\\t', test_df.shape)\n",
    "\n",
    "print('\\nTrain Landmarks:\\t', len(train_df['landmark_id'].unique()))\n",
    "print('Validation Landmarks:\\t', len(val_df['landmark_id'].unique()))\n",
    "print('Test Landmarks:\\t\\t', len(test_df['landmark_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465272</td>\n",
       "      <td>a2ccf8ed2e969f6a</td>\n",
       "      <td>https://lh4.googleusercontent.com/-TPHkS5gzvm4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64516</td>\n",
       "      <td>e205ca7c8dd7c027</td>\n",
       "      <td>https://lh3.googleusercontent.com/-V3RjsZtGpxE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928409</td>\n",
       "      <td>4e8ab93c1620e8a3</td>\n",
       "      <td>http://mw2.google.com/mw-panoramio/photos/medi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88809</td>\n",
       "      <td>896bf928214d1ca4</td>\n",
       "      <td>http://lh5.ggpht.com/-Cy0l41uUaGA/R--yB8vy41I/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001133</td>\n",
       "      <td>375d2a153bdca926</td>\n",
       "      <td>http://lh6.ggpht.com/-UqzFpnqE9bU/S_0u1RovfdI/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                id  \\\n",
       "0    465272  a2ccf8ed2e969f6a   \n",
       "1     64516  e205ca7c8dd7c027   \n",
       "2    928409  4e8ab93c1620e8a3   \n",
       "3     88809  896bf928214d1ca4   \n",
       "4   1001133  375d2a153bdca926   \n",
       "\n",
       "                                                 url  landmark_id  \n",
       "0  https://lh4.googleusercontent.com/-TPHkS5gzvm4...            0  \n",
       "1  https://lh3.googleusercontent.com/-V3RjsZtGpxE...            0  \n",
       "2  http://mw2.google.com/mw-panoramio/photos/medi...            0  \n",
       "3  http://lh5.ggpht.com/-Cy0l41uUaGA/R--yB8vy41I/...            0  \n",
       "4  http://lh6.ggpht.com/-UqzFpnqE9bU/S_0u1RovfdI/...            0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all images\n",
    "def get_all_images(df, img_size=(224, 224), prefix='./data/triplet/train'):\n",
    "    \"\"\" get all test images \"\"\"\n",
    "    img_ids = df['image_id'].values\n",
    "    landmark_ids = df['landmark_id'].values\n",
    "    images = []\n",
    "    \n",
    "    for idx in img_ids:\n",
    "        path = prefix + str(idx) + '.jpg'\n",
    "        tmp_img = load_img(path, target_size=img_size)\n",
    "        tmp_img = img_to_array(tmp_img)\n",
    "        images.append(tmp_img)\n",
    "        \n",
    "    # transform list to array\n",
    "    images = np.array(images, dtype=K.floatx()) / 255.0\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set triplet generator\n",
    "def train_triplet_generator(df, batch_size=42, img_size=(224, 224), seed=42, \n",
    "                            prefix='./data/triplet/train/'):\n",
    "    \"\"\" training set triplet generator\n",
    "        it will generate 7400 triplet images in total\n",
    "    \"\"\"\n",
    "    # get images with only one training image landmark id and the rest landmark ids\n",
    "    np.random.seed(seed)\n",
    "    grouped = df[['landmark_id', 'image_id']].groupby('landmark_id').count().reset_index()\n",
    "    unique_neg_ids = list(grouped[grouped['image_id'] == 1]['landmark_id'].values)\n",
    "    rest_ids = list(grouped[grouped['image_id'] > 1]['landmark_id'].values)\n",
    "    size = 7400 * 2 - len(unique_neg_ids) \n",
    "    \n",
    "    while True:\n",
    "        # get positive and negative image landmark ids\n",
    "        np.random.shuffle(rest_ids)\n",
    "        candidate_ids = list(np.random.choice(rest_ids, size=size, replace=False))\n",
    "        pos_landmark_ids = candidate_ids[:7400]\n",
    "        neg_landmark_ids = candidate_ids[7400:] + unique_neg_ids\n",
    "        np.random.shuffle(neg_landmark_ids)\n",
    "        \n",
    "        # transform landmark id into image id\n",
    "        anc_img_ids = []\n",
    "        pos_img_ids = []\n",
    "        neg_img_ids = []\n",
    "        \n",
    "        for i in range(len(pos_landmark_ids)):\n",
    "            tmp_pos_ids = df[df['landmark_id'] == pos_landmark_ids[i]]['image_id'].values\n",
    "            anc_img_ids.append(tmp_pos_ids[0])\n",
    "            pos_img_ids.append(tmp_pos_ids[1])\n",
    "            \n",
    "            tmp_neg_ids = df[df['landmark_id'] == neg_landmark_ids[i]]['image_id'].values\n",
    "            neg_img_ids.append(tmp_neg_ids[0])\n",
    "        \n",
    "        # iterator to read batch images\n",
    "        for j in range(len(pos_img_ids) // batch_size):\n",
    "            batch_anc_img_ids = anc_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_pos_img_ids = pos_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_neg_img_ids = neg_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            \n",
    "            # get images\n",
    "            anc_imgs = []\n",
    "            pos_imgs = []\n",
    "            neg_imgs = []\n",
    "            \n",
    "            # iteratively read images\n",
    "            for k in range(batch_size):\n",
    "                anc_path = prefix + str(batch_anc_img_ids[k]) + '.jpg'\n",
    "                pos_path = prefix + str(batch_pos_img_ids[k]) + '.jpg'\n",
    "                neg_path = prefix + str(batch_neg_img_ids[k]) + '.jpg'\n",
    "                \n",
    "                tmp_anc_img = load_img(anc_path, target_size=img_size)\n",
    "                tmp_anc_img = img_to_array(tmp_anc_img)\n",
    "                anc_imgs.append(tmp_anc_img)\n",
    "                \n",
    "                tmp_pos_img = load_img(pos_path, target_size=img_size)\n",
    "                tmp_pos_img = img_to_array(tmp_pos_img)\n",
    "                pos_imgs.append(tmp_pos_img)\n",
    "                \n",
    "                tmp_neg_img = load_img(neg_path, target_size=img_size)\n",
    "                tmp_neg_img = img_to_array(tmp_neg_img)\n",
    "                neg_imgs.append(tmp_neg_img)\n",
    "        \n",
    "            # transform list to array\n",
    "            anc_imgs = np.array(anc_imgs, dtype=K.floatx()) / 255.0\n",
    "            pos_imgs = np.array(pos_imgs, dtype=K.floatx()) / 255.0\n",
    "            neg_imgs = np.array(neg_imgs, dtype=K.floatx()) / 255.0\n",
    "\n",
    "            zeros = np.zeros((batch_size, 1), dtype=K.floatx())\n",
    "            \n",
    "#             yield {'anchor_input': anc_imgs, 'positive_input': pos_imgs, 'negative_input': neg_imgs}\n",
    "            yield [anc_imgs, pos_imgs, neg_imgs], [zeros, zeros, zeros]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set triplet generator\n",
    "def val_triplet_generator(df, batch_size=128, img_size=(224, 224), \n",
    "                          seed=42, prefix='./data/triplet/validation'):\n",
    "    \"\"\" validation set triplet collector \"\"\"\n",
    "    \n",
    "     # get images with only one image landmark id and the rest landmark ids\n",
    "    grouped = df[['landmark_id', 'image_id']].groupby('landmark_id').count().reset_index()\n",
    "    unique_neg_ids = list(grouped[grouped['image_id'] == 1]['landmark_id'].values)\n",
    "    rest_ids = list(grouped[grouped['image_id'] > 1]['landmark_id'].values)\n",
    "    size = 3072 * 2 - len(unique_neg_ids) \n",
    "    \n",
    "    while True:\n",
    "        # get positive and negative image landmark ids\n",
    "        np.random.seed(42)\n",
    "        candidate_ids = list(np.random.choice(rest_ids, size=size, replace=False))\n",
    "        pos_landmark_ids = candidate_ids[:3072]\n",
    "        neg_landmark_ids = candidate_ids[3072:] + unique_neg_ids\n",
    "        np.random.shuffle(neg_landmark_ids)\n",
    "        \n",
    "        # transform landmark id into image id\n",
    "        anc_img_ids = []\n",
    "        pos_img_ids = []\n",
    "        neg_img_ids = []\n",
    "        \n",
    "        for i in range(len(pos_landmark_ids)):\n",
    "            tmp_pos_ids = df[df['landmark_id'] == pos_landmark_ids[i]]['image_id'].values\n",
    "            anc_img_ids.append(tmp_pos_ids[0])\n",
    "            pos_img_ids.append(tmp_pos_ids[1])\n",
    "            \n",
    "            tmp_neg_ids = df[df['landmark_id'] == neg_landmark_ids[i]]['image_id'].values\n",
    "            neg_img_ids.append(tmp_neg_ids[0])\n",
    "        \n",
    "        # iterator to read batch images\n",
    "        for j in range(len(pos_img_ids) // batch_size):\n",
    "            batch_anc_img_ids = anc_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_pos_img_ids = pos_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_neg_img_ids = neg_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            \n",
    "            # get images\n",
    "            anc_imgs = []\n",
    "            pos_imgs = []\n",
    "            neg_imgs = []\n",
    "            \n",
    "            # iteratively read images\n",
    "            for k in range(batch_size):\n",
    "                anc_path = prefix + str(batch_anc_img_ids[k]) + '.jpg'\n",
    "                pos_path = prefix + str(batch_pos_img_ids[k]) + '.jpg'\n",
    "                neg_path = prefix + str(batch_neg_img_ids[k]) + '.jpg'\n",
    "                \n",
    "                tmp_anc_img = load_img(anc_path, target_size=img_size)\n",
    "                tmp_anc_img = img_to_array(tmp_anc_img)\n",
    "                anc_imgs.append(tmp_anc_img)\n",
    "                \n",
    "                tmp_pos_img = load_img(pos_path, target_size=img_size)\n",
    "                tmp_pos_img = img_to_array(tmp_pos_img)\n",
    "                pos_imgs.append(tmp_pos_img)\n",
    "                \n",
    "                tmp_neg_img = load_img(neg_path, target_size=img_size)\n",
    "                tmp_neg_img = img_to_array(tmp_neg_img)\n",
    "                neg_imgs.append(tmp_neg_img)\n",
    "        \n",
    "            # transform list to array\n",
    "            anc_imgs = np.array(anc_imgs, dtype=K.floatx()) / 255.0\n",
    "            pos_imgs = np.array(pos_imgs, dtype=K.floatx()) / 255.0\n",
    "            neg_imgs = np.array(neg_imgs, dtype=K.floatx()) / 255.0\n",
    "            \n",
    "            zeros = np.zeros((batch_size, 1), dtype=K.floatx())\n",
    "            \n",
    "#             yield {'anchor_input': anc_imgs, 'positive_input': pos_imgs, 'negative_input': neg_imgs}\n",
    "            yield [anc_imgs, pos_imgs, neg_imgs], [zeros, zeros, zeros]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Triplet Loss Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base network for triplet network\n",
    "def base_net(input_shape=(150, 150, 3), trainable=False):\n",
    "    \"\"\" define triplet network \"\"\"\n",
    "    # load pre-trained VGG16 model\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    vgg16.trainable = trainable\n",
    "    \n",
    "    # define sequential model\n",
    "    model = Sequential(name='base_net')\n",
    "    model.add(vgg16)\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(512, activation='relu', name='fc1'))\n",
    "    model.add(Dense(128, activation=None, name='fc2'))\n",
    "    model.add(Lambda(lambda x: K.l2_normalize(x, axis=1), name='l2_norm'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define triplet network\n",
    "def triplet_net(base_model, input_shape=(150, 150, 3)):\n",
    "    \"\"\" function to define triplet networks \"\"\"\n",
    "    # define input: anchor, positive, negative\n",
    "    anchor = Input(shape=input_shape, name='anchor_input')\n",
    "    positive = Input(shape=input_shape, name='positive_input')\n",
    "    negative = Input(shape=input_shape, name='negative_input')\n",
    "    \n",
    "    # extract vector represent using CNN based model\n",
    "    anchor_vec = base_model(anchor)\n",
    "    pos_vec = base_model(positive)\n",
    "    neg_vec = base_model(negative)\n",
    "    \n",
    "    # define inputs and outputs\n",
    "    inputs=[anchor, positive, negative]\n",
    "    outputs=[anchor_vec, pos_vec, neg_vec]\n",
    "    \n",
    "    # define the triplet model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='triplet_net')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define triplet loss\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    \"\"\" function to compute triplet loss\n",
    "        margin is predefined coded, manually change if needed\n",
    "    \"\"\"\n",
    "    # define triplet margin\n",
    "    margin = 0.2\n",
    "    \n",
    "    # get the prediction vector\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    # compute distance\n",
    "    pos_distance = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), axis=-1)\n",
    "    neg_distance = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), axis=-1)\n",
    "    \n",
    "    # compute loss\n",
    "    partial_loss = tf.subtract(pos_distance, neg_distance) + margin\n",
    "    full_loss = tf.reduce_sum(tf.maximum(partial_loss, 0.0))\n",
    "    \n",
    "    return full_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# img_size = (224, 224, 3)  # target image size\n",
    "\n",
    "# #Summary of pre-trained VGG16 model\n",
    "# vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=img_size)\n",
    "# vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model test\n",
    "# base_model = base_net(input_shape=img_size, trainable=False)\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model test\n",
    "# triplet_model = triplet_net(base_model=base_model, input_shape=img_size)\n",
    "# triplet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproduciable purpose\n",
    "seed = 42\n",
    "K.clear_session()\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(seed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# Define Parameters\n",
    "img_size = (224, 224, 3)  # target image size\n",
    "\n",
    "# triplet image generator\n",
    "train_generator = train_triplet_generator(train_df, batch_size=128, img_size=img_size[:2], \n",
    "                                          seed=42, prefix='./data/triplet/train/')\n",
    "\n",
    "val_generator = val_triplet_generator(val_df, batch_size=128, img_size=img_size[:2], \n",
    "                                      seed=42, prefix='./data/triplet/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define triplet network model\n",
    "base_model = base_net(input_shape=img_size, trainable=False)\n",
    "triplet_model = triplet_net(base_model=base_model, input_shape=img_size)\n",
    "\n",
    "# define optimizer\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# compile the model\n",
    "triplet_model.compile(optimizer=opt, loss=triplet_loss)\n",
    "\n",
    "# Create call backs\n",
    "checkpoint = ModelCheckpoint(filepath='./models/triplet-initial-ckpt.h5')\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "callbacks = [checkpoint, lr_reducer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " - 20s - loss: 0.7900 - base_net_loss: 0.3000 - val_loss: 0.5793 - val_base_net_loss: 0.2042\n",
      "Epoch 2/2\n",
      " - 19s - loss: 0.6188 - base_net_loss: 0.2222 - val_loss: 0.5738 - val_base_net_loss: 0.2036\n"
     ]
    }
   ],
   "source": [
    "# fit the mode\n",
    "history = triplet_model.fit_generator(train_generator, steps_per_epoch=1, epochs=2, verbose=2, \n",
    "                                      callbacks=callbacks, validation_data=val_generator, validation_steps=24)\n",
    "\n",
    "triplet_model.save('./models/triplet-initial-model.h5')\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
